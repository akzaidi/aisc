# AI Safety Camp: Creating Alignment Failures in GPT-3

#safety, #alignment

## Team

- Kyle & Laria, EleutherAI
- Arun Jose
- Ameya P
- Ali Z

## Examples of Alignment Failures

1. Semantic Drift
2. Honesty
3. Toxicity
4. Unintended Memorization

## Experiments

## Interesting Papers

- [Multitasking Inhibits Semantic Drift](https://arxiv.org/abs/2104.07219), Athul Paul Jacob, Mike Lewis, Jacob Andreas
- [A General Language Assistant as a Laboratory for Alignment](https://arxiv.org/abs/2112.00861), AnthropicAI
- [TruthfulQA](https://arxiv.org/abs/2109.07958), Stephanie Lin, Jacob Hilton, Owain Evans
- [Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325), OpenAI